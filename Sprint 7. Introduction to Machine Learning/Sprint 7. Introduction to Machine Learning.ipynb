{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employing Machine Learning to Suggest Optimal Data Plans for Clients\n",
    "\n",
    "Megaline, a mobile carrier, has noticed that a significant number of its subscribers are still utilizing outdated data plans. The company intends to propose a newer data plan to each legacy plan user, with the goal of ensuring that the recommended plan is the most appropriate for each customer. To achieve this, Megaline has requested to train a model that will determine which of the new data plans offered by Megaline (Smart or Ultra) would be the best fit for each customer based on their data usage habits\n",
    "\n",
    "As the recommendation can either be the Smart or Ultra plan, this is a binary classification problem. In order to solve this problem, the following machine learning models will be trained and evaluated:\n",
    "\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "\n",
    "The overall data will be divided into training, validation, and testing sets. Both models will be trained and fine-tuned using the training and validation sets, with the aim of optimizing the hyperparameters for maximum accuracy. Once the optimal hyperparameters are established, the models will be evaluated using the test set and the one with the highest accuracy will be selected as the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Below, the csv file `users_behavior.csv` will be read and stored in the DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and store it to df\n",
    "\n",
    "df = pd.read_csv('users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "\n",
    "Let's take a look at the data stored in the `df` DataFrame. The first 15 rows will be printed, followed by the general info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58.0</td>\n",
       "      <td>344.56</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15823.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.0</td>\n",
       "      <td>431.64</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3738.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.0</td>\n",
       "      <td>132.40</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21911.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>43.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2538.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90.0</td>\n",
       "      <td>665.41</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17358.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>82.0</td>\n",
       "      <td>560.51</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9619.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>45.0</td>\n",
       "      <td>344.32</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19898.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>51.0</td>\n",
       "      <td>437.13</td>\n",
       "      <td>61.0</td>\n",
       "      <td>21523.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>56.0</td>\n",
       "      <td>433.07</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16702.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>108.0</td>\n",
       "      <td>587.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14406.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    calls  minutes  messages   mb_used  is_ultra\n",
       "0    40.0   311.90      83.0  19915.42         0\n",
       "1    85.0   516.75      56.0  22696.96         0\n",
       "2    77.0   467.66      86.0  21060.45         0\n",
       "3   106.0   745.53      81.0   8437.39         1\n",
       "4    66.0   418.74       1.0  14502.75         0\n",
       "5    58.0   344.56      21.0  15823.37         0\n",
       "6    57.0   431.64      20.0   3738.90         1\n",
       "7    15.0   132.40       6.0  21911.60         0\n",
       "8     7.0    43.39       3.0   2538.67         1\n",
       "9    90.0   665.41      38.0  17358.61         0\n",
       "10   82.0   560.51      20.0   9619.53         1\n",
       "11   45.0   344.32      13.0  19898.81         0\n",
       "12   51.0   437.13      61.0  21523.58         0\n",
       "13   56.0   433.07      16.0  16702.36         0\n",
       "14  108.0   587.90       0.0  14406.50         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first 15 rows\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Look at summary of the DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame does not have any missing values and the data types are suitable as they are. The `calls` and `messages` columns may have integer values instead of float values, but keeping them as float values will not affect the modeling process. Therefore, no further data preparation is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "The data was loaded and inspected\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two machine learning algorithms will be employed:\n",
    "\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "\n",
    "The models with the highest accuracy will be chosen for final testing. The models will be evaluated using the test data and their accuracy will be measured to determine their performance and which model is superior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into datasets\n",
    "\n",
    "The column `is_ultra` indicates the plan used by a customer, it contains a 0 if the Smart plan is used, and a 1 if the Ultra plan is used. Since we aim to recommend a plan to customers based on their data usage habits, the column `is_ultra` will be our target column. The other columns (`calls`, `minutes`, `messages`, `mb_used`) provide information about each customer's data usage behavior and have some influence on their decision to enroll in the Smart or Ultra plan, so these columns will be our feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The features of the DataFrame include all columns except for 'is_ultra'\n",
    "features = df.drop('is_ultra', axis=1)\n",
    "\n",
    "# The target of the DataFrame is the 'is_ultra' column\n",
    "target = df['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `features` DataFrame and `target` Series data will be divided into training, validation, and test datasets with a ratio of 3:1:1. Specifically, the training, validation, and test datasets will consist of 60%, 20%, and 20% of the data from `features` and `target`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the above slices into training, validation, and test datasets...\n",
    "#First, split the training datasets apart from the validation and test data. \n",
    "#This will be done by splitting the data into the train datasets and \"other\" datasets. \n",
    "#The \"other\" datasets will have a test_size of 0.4, or 40% of the data, leaving the training datasets with 60% of the data.\n",
    "\n",
    "features_train, features_other, target_train, target_other  = train_test_split(features, target, test_size=0.4,\\\n",
    "                                                                               random_state=12345)\n",
    "\n",
    "#Split the \"other\" datasets to create the validation and test datasets. \n",
    "#Since the \"other\" dataset account for 40% of the original data and the validation and test datasets \n",
    "#should each contain 20% of the original data, the\"other\" datasets will be split in half. \n",
    "#So, the test_size parameter will be set to 0.5 (for 50%).\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_other, target_other, test_size=0.5,\\\n",
    "                                                                            random_state=12345)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the target column has binary values, 0 or 1, the task of predicting the target values is a binary classification task. A decision tree model is a suitable algorithm to use for this type of task. The maximum depth of the tree is a crucial hyperparameter in decision tree model. Therefore, the following code block will create different models with varying maximum depths. The accuracy of each model will be evaluated, and the model with the highest accuracy will be presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: DecisionTreeClassifier(max_depth=3, random_state=12345)\n",
      "Best Accuracy: 78.54%\n",
      "Best Depth: 3\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Model/Learning Algorithm\n",
    "\n",
    "# Initialize\n",
    "best_model = None\n",
    "best_DT_accuracy = 0\n",
    "best_depth = 0\n",
    "\n",
    "# Create various models with different depth values\n",
    "\n",
    "# for loop for changing depth values (range of 1-41)\n",
    "for depth in range(1,41):\n",
    "    \n",
    "    # Create a model, using the provided depth and the same random_state\n",
    "    DT_model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    \n",
    "    # Train the model using the training dataset\n",
    "    DT_model.fit(features_train, target_train)\n",
    "    \n",
    "    # Predict the target values of the validation features using the model\n",
    "    DT_predictions_valid = DT_model.predict(features_valid) # get model predictions on validation set\n",
    "    \n",
    "    # Calculate the accuracy, if allowed\n",
    "    try:\n",
    "        accuracy = accuracy_score(target_valid, DT_predictions_valid)\n",
    "    except:\n",
    "        break\n",
    "    \n",
    "    # Determe best fit\n",
    "    if accuracy > best_DT_accuracy:\n",
    "        best_DT_model = DT_model\n",
    "        best_DT_depth = depth\n",
    "        best_DT_accuracy = accuracy\n",
    "\n",
    "print('Best Model:', best_DT_model)\n",
    "print(f'Best Accuracy: {round(best_DT_accuracy*100,2)}%')\n",
    "print('Best Depth:', best_DT_depth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree model with the highest accuracy is the one with a maximum depth of 3, which achieved an accuracy of around 78.54%. This model will be referred to as `best_DT_model` and will be utilized during the testing phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest model\n",
    "\n",
    "Now, let's use a random forest model to predict the target values. The maximum depth and the number of estimators are important hyperparameters for a random forest model. The number of estimators is equivalent to the number of decision trees in the model. To identify the optimal combination of hyperparameters, models will be trained and evaluated with different values of both the maximum depth and number of estimators. This will be done by using nested for loops to iterate through a range of values for each hyperparameter. All the resulting models will be evaluated for accuracy, and the random forest model with the highest accuracy will be presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: RandomForestClassifier(max_depth=12, n_estimators=17, random_state=12345)\n",
      "Best Accuracy: 80.56%\n",
      "Best Depth: 12\n",
      "Best n_estimators: 17\n"
     ]
    }
   ],
   "source": [
    "# Random Forest model\n",
    "\n",
    "# Initialize\n",
    "best_model = None\n",
    "best_result = 10000\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "best_score = 0\n",
    "best_RF_accuracy = 0\n",
    "\n",
    "# Create various models with different depth and estimator values\n",
    "\n",
    "# for loop for the number of estimators\n",
    "for est in range(1,21):\n",
    "    \n",
    "    # for loop for the depth value\n",
    "    for depth in range (1, 41):\n",
    "        \n",
    "        # Create a model, using the provided depth, number of estimators, and the same random_state\n",
    "        RF_model = RandomForestClassifier(max_depth=depth, random_state=12345, n_estimators=est)\n",
    "        \n",
    "        # Train the model using the training dataset\n",
    "        RF_model.fit(features_train, target_train)\n",
    "\n",
    "        # Predict the target values of the validation features using the model\n",
    "        RF_predictions_valid = RF_model.predict(features_valid) # get model predictions on validation set\n",
    "       \n",
    "        # Calculate the accuracy, if allowed\n",
    "        try:\n",
    "            accuracy = accuracy_score(target_valid, RF_predictions_valid)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "     # Determe best fit\n",
    "        if accuracy > best_RF_accuracy:\n",
    "            best_RF_model = RF_model\n",
    "            best_RF_accuracy = accuracy\n",
    "            best_RF_depth = depth\n",
    "            best_est = est\n",
    "\n",
    "print('Best Model:', best_RF_model)\n",
    "print(f'Best Accuracy: {round(best_RF_accuracy*100,2)}%')\n",
    "print('Best Depth:', best_RF_depth)\n",
    "print('Best n_estimators:', best_est)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model that achieved the highest accuracy has a maximum depth of 12, a number of estimators value of 17, and an accuracy of around 80.56%. This model will be referred to as `best_RF_model` and will be used during the testing phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model\n",
    "\n",
    "The optimal hyperparameters for both the decision tree and random forest models have been identified. The best models of each type have been saved as `best_DT_model` and `best_RF_model`. Now, it is time to evaluate these models by using them to predict the target values of the test datasets and calculating the accuracy of each model.\n",
    "\n",
    "### Best decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.54%\n"
     ]
    }
   ],
   "source": [
    "# Test the final decision tree model using the valid dataset\n",
    "\n",
    "# Predict the target values\n",
    "DT_validation_predictions = best_DT_model.predict(features_valid)\n",
    "\n",
    "# Calculate the accuracy\n",
    "DT_validation_accuracy = accuracy_score(target_valid, DT_validation_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {round(DT_validation_accuracy*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best decision tree model achieved an accuracy of 78.54% when making predictions on the test dataset, which is higher than the threshold of 75% for model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.56%\n"
     ]
    }
   ],
   "source": [
    "# Test the final random forest model using the valid dataset\n",
    "\n",
    "# Predict the target values\n",
    "RF_validation_predictions = best_RF_model.predict(features_valid)\n",
    "\n",
    "# Calculate the accuracy\n",
    "RF_validation_accuracy = accuracy_score(target_valid, RF_validation_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {round(RF_validation_accuracy*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best random forest model was found to be more accurate than the best decision tree model, with an accuracy of 80.56% when predicting on the test dataset. This accuracy is above the threshold of 75% for model performance and surpasses the 78.54% accuracy of the decision tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.23%\n"
     ]
    }
   ],
   "source": [
    "# Select the best model based on the validation accuracy\n",
    "if DT_validation_accuracy > RF_validation_accuracy:\n",
    "    best_model = DT_model\n",
    "else:\n",
    "    best_model = RF_model\n",
    "    \n",
    "# Test the final selected model using the test dataset\n",
    "test_predictions = best_model.predict(features_test)\n",
    "test_accuracy = accuracy_score(target_test, test_predictions)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {round(test_accuracy*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final selected model, which was a decision tree, achieved an accuracy of 78.23% on the test dataset, indicating that the model is able to accurately predict the target variable with a high degree of certainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each user can either be recommended the Smart or Ultra plan, which correlates to either a 0 or 1 in the target datasets or predicted values. Since determining which plan to recommend is a binary classification task, there is a baseline accuracy that can be achieved by always predicting the majority class. This baseline is equal to the proportion of the majority class in the dataset.\n",
    "\n",
    "In this case, if the majority class is the Smart plan, then the baseline accuracy would be around 70%. The final decision tree model and the final random forest model had an accuracy of 78.54% and 80.56%, respectively. These numbers are significantly larger than the 70% accuracy that would be attained by always recommending the majority class. Thus, it makes sense to utilize either of the final trained models obtained to determine which plan to recommend to each customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The mobile carrier Megaline requested a trained model that would recommend one of their newer plans to customers continuing to use legacy plans. It was determined that this was a binary classification task since only the Ultra or Smart plan could be recommended. Therefore, the two models that were trained were a decision tree model and a random forest model.\n",
    "\n",
    "The features and target data were divided into 3 datasets as follows:\n",
    "\n",
    "Training dataset (60%)\n",
    "Validation dataset (20%)\n",
    "Testing dataset (20%)\n",
    "Multiple models were created with various combinations of hyperparameters. They were trained with the same data, and then their accuracy was comapred. The decision tree model and random forest model with the highest accuracy were then tested using the testing data. The accuracy of the best decision tree model was calculated to be 78.54%, and the accuracy of the best random forest model was calculated to be 80.56%. Both models surpass the 75% accuracy threshold. The best random forest model is slightly more accurate than the best decision tree model, so that should be the model delivered to Megaline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
